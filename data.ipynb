{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 패션 이미지 데이터셋 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# path = 'data/meta/'\n",
    "# train = pd.read_json(path + 'train_no_dup.json')\n",
    "# valid = pd.read_json(path + 'valid_no_dup.json')\n",
    "# test = pd.read_json(path + 'test_no_dup.json')\n",
    "# blank = pd.read_json(path + 'fill_in_blank_test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dataloader.sampling import DataSampler\n",
    "from dataloader.multimodal_data import MultiModalData\n",
    "import os\n",
    "\n",
    "base_dir = os.getcwd()\n",
    "data_dir = os.path.join(base_dir, 'data')\n",
    "meta_dir = os.path.join(data_dir, 'meta')\n",
    "image_dir = os.path.join(data_dir, 'images')\n",
    "sampler = DataSampler(data_path = meta_dir, k=150, test_sampling_ratio=1)\n",
    "concat_df, question_data = sampler.sample_data()\n",
    "\n",
    "train_dataset = MultiModalData(concat_df, sampler.category_df, image_dir, mode='train')\n",
    "valid_dataset = MultiModalData(concat_df, sampler.category_df, image_dir, mode='valid')\n",
    "test_dataset = MultiModalData(concat_df, sampler.category_df, image_dir, question = question_data, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\jin\\Lib\\site-packages\\torch\\nn\\functional.py:5560: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['texts', 'prices', 'likes', 'images', 'set_id', 'question', 'valid_idx', 'gt_idx'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[10].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'texts': tensor([[ 0.1232,  0.3848, -0.2727,  ...,  0.3809,  0.4153,  0.0362],\n",
       "         [-0.1003,  0.5273, -0.3535,  ...,  0.3945, -0.3074,  0.4644],\n",
       "         [ 0.0574, -0.1785, -0.0731,  ...,  0.3362,  0.1958,  0.0703],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "        device='cuda:0', grad_fn=<CatBackward0>),\n",
       " 'text_gt': tensor([ 2.9199e-01, -4.5557e-01, -3.7427e-01,  2.5244e-01, -1.6760e-01,\n",
       "          2.9956e-01, -2.4353e-01, -2.8101e-01,  2.9639e-01,  2.6685e-01,\n",
       "         -2.1375e-01, -5.0977e-01,  2.3926e-01, -8.7952e-02, -1.8005e-01,\n",
       "          2.0483e-01, -2.8149e-01, -5.9204e-02, -5.6982e-01,  4.3579e-01,\n",
       "         -5.4474e-02, -1.9897e-02,  2.4951e-01,  6.0120e-03,  2.7881e-01,\n",
       "         -1.6821e-01, -3.1152e-01, -6.7688e-02, -3.0957e-01, -1.5881e-01,\n",
       "         -2.0508e-01, -1.1725e-01,  1.8628e-01, -5.2686e-01, -5.8398e-01,\n",
       "         -9.5154e-02,  1.1664e-01,  5.2490e-01,  1.2347e-01,  3.0273e-02,\n",
       "          2.9321e-01, -1.6504e-01, -1.4270e-01, -3.6816e-01, -1.5576e-01,\n",
       "          7.8857e-02,  1.5662e-01,  1.6919e-01,  5.0488e-01,  6.2683e-02,\n",
       "          9.0698e-02, -8.1787e-01, -1.4001e-01, -1.1456e-01,  9.8328e-02,\n",
       "         -1.9873e-01,  4.8022e-01, -2.3669e-01, -2.5928e-01, -2.4402e-01,\n",
       "          1.9550e-03,  1.1420e-01,  2.9150e-01, -1.6821e-01, -2.0789e-01,\n",
       "          1.2769e-01,  2.3560e-01,  1.4929e-01,  1.5576e-01,  1.4172e-01,\n",
       "         -7.0007e-02, -5.0244e-01,  4.7119e-02, -2.4207e-01,  4.1870e-01,\n",
       "         -2.0752e-01,  7.5623e-02,  2.8961e-02,  1.2720e-01,  5.3906e-01,\n",
       "         -2.5220e-01, -1.3135e-01,  2.5610e-01,  3.9673e-02, -4.0186e-01,\n",
       "          8.1100e-03,  3.1464e-02,  1.2805e-01, -6.6602e-01, -1.5076e-01,\n",
       "          7.1228e-02, -3.3447e-01, -7.4121e-01,  7.4365e-01, -8.4106e-02,\n",
       "          2.9077e-01,  2.7374e-02, -4.8218e-01,  7.3120e-02,  1.8707e-02,\n",
       "          2.8296e-01,  1.0071e-01,  6.7261e-02,  3.3472e-01,  3.7085e-01,\n",
       "          3.6792e-01,  1.2061e-01, -1.1469e-01, -3.3594e-01,  1.0638e-01,\n",
       "         -6.6162e-02,  4.3579e-02,  2.7588e-01,  2.8662e-01,  1.6882e-01,\n",
       "          1.7981e-01,  1.3115e-02,  1.2550e-02, -1.0120e-01,  1.5152e-02,\n",
       "          2.8638e-01, -2.5781e-01, -5.1804e-03,  4.4037e-02,  1.4587e-01,\n",
       "          4.9194e-01,  3.4607e-02, -3.2812e-01, -1.7664e-01,  1.4671e-02,\n",
       "          5.0146e-01,  1.5222e-01, -2.0581e-01,  3.3359e+00, -3.2324e-01,\n",
       "          1.7651e-01,  1.0551e-02, -1.2122e-01,  3.6377e-01, -1.0513e-02,\n",
       "          6.3049e-02, -1.0181e-01, -1.3306e-02, -1.1646e-01,  1.7163e-01,\n",
       "          6.5552e-02,  6.5369e-02, -2.1912e-01, -3.5596e-01,  2.5977e-01,\n",
       "         -1.4209e-01,  4.4971e-01,  4.2676e-01, -3.3154e-01, -1.8311e-01,\n",
       "          2.8516e-01,  3.3179e-01,  1.4172e-01, -7.2823e-03,  2.2430e-02,\n",
       "         -2.4573e-01,  1.4124e-01, -3.3472e-01,  1.3708e-01, -5.0415e-02,\n",
       "          3.1885e-01,  6.1084e-01,  6.5231e-03,  3.0640e-01,  2.6538e-01,\n",
       "         -2.3926e-01,  4.0308e-01,  1.8201e-01, -4.9976e-01, -1.0338e-02,\n",
       "         -1.7419e-01,  6.9385e-01, -4.5807e-02,  1.3293e-01,  3.6255e-01,\n",
       "         -8.5354e-05, -2.1045e-01, -1.9482e-01, -2.4121e-01,  3.4546e-02,\n",
       "         -4.1675e-01,  1.0651e-01, -3.5938e-01, -9.2529e-02,  9.2773e-02,\n",
       "         -3.2318e-02, -1.9592e-01,  2.2375e-01, -1.9214e-01,  6.9885e-02,\n",
       "          1.7761e-01,  2.1216e-01,  1.2177e-01, -2.1896e-02,  1.5784e-01,\n",
       "         -1.1658e-01,  1.8347e-01, -1.2009e-02, -2.0190e-01,  2.8992e-02,\n",
       "          1.7017e-01,  3.7866e-01, -1.0828e-01,  3.0542e-01,  2.5098e-01,\n",
       "          3.2104e-02, -4.7913e-02, -2.8516e-01, -2.0435e-01, -6.8848e-02,\n",
       "          4.7583e-01, -4.7485e-01, -5.0000e-01, -2.8027e-01,  4.2206e-02,\n",
       "         -3.4409e-03, -4.5630e-01,  1.1520e-02, -4.1412e-02, -1.3779e-02,\n",
       "          4.8584e-01,  1.2769e-01,  3.0861e-03, -1.5515e-01, -1.3672e-01,\n",
       "         -2.7686e-01, -2.7206e-02,  6.2500e-02, -1.8848e-01,  4.6356e-02,\n",
       "         -3.4082e-01, -2.2803e-01,  9.3506e-02,  1.9165e-01,  1.6937e-02,\n",
       "         -1.3574e-01, -4.2419e-02, -3.4033e-01,  1.8127e-01, -3.2764e-01,\n",
       "         -2.3157e-01, -2.7539e-01,  9.9731e-02,  2.0361e-01, -1.2756e-01,\n",
       "         -2.1606e-01,  3.5767e-02, -3.1921e-02, -6.6357e-01, -1.7871e-01,\n",
       "          3.3521e-01, -2.1423e-01, -5.1636e-02, -9.4360e-02, -2.1667e-01,\n",
       "          3.8086e-01,  5.2637e-01, -1.2610e-01, -2.6294e-01, -6.1035e-01,\n",
       "          2.0898e-01,  1.9470e-01,  1.8518e-01,  1.8872e-01, -8.3191e-02,\n",
       "         -1.1206e-01, -2.8534e-02, -1.4221e-01, -2.0605e-01, -3.5278e-01,\n",
       "         -2.8198e-01,  2.5000e-01, -3.5449e-01, -8.4229e-02, -2.8784e-01,\n",
       "         -1.1835e-01,  5.8008e-01, -5.6006e-01,  1.6504e-01, -2.1326e-01,\n",
       "          6.4758e-02,  5.9937e-02,  4.5776e-01, -4.2297e-02, -2.5098e-01,\n",
       "         -4.0359e-03,  3.4375e-01,  2.8003e-01, -2.9614e-01,  2.7075e-01,\n",
       "         -3.1421e-01, -4.6655e-01, -1.1102e-01,  1.6211e-01,  1.1566e-02,\n",
       "         -2.5854e-01, -5.9668e-01,  3.6841e-01,  1.6199e-01,  2.0630e-01,\n",
       "          6.6345e-02,  1.3586e-01, -1.7151e-01, -5.2783e-01, -5.8380e-02,\n",
       "         -2.3523e-01,  5.5127e-01,  3.3379e+00,  1.0980e-01,  1.7883e-01,\n",
       "         -2.7832e-01, -2.4768e-01, -3.4229e-01, -2.5684e-01, -4.0894e-02,\n",
       "          1.7896e-01,  1.3123e-01, -9.5581e-02,  1.1688e-01, -2.6953e-01,\n",
       "         -9.3445e-02,  6.9214e-02, -2.7490e-01,  1.2610e-01, -7.6270e-01,\n",
       "          5.4443e-01,  1.8079e-01,  2.3401e-01, -4.3994e-01,  1.8750e-01,\n",
       "         -5.9448e-02, -3.3618e-01, -7.2998e-02,  1.0504e-01, -1.6772e-01,\n",
       "          1.8021e-02, -1.3708e-01, -1.9836e-01,  1.2238e-01, -5.7275e-01,\n",
       "          5.8319e-02,  2.5073e-01,  2.0935e-01, -8.1116e-02,  1.2030e-01,\n",
       "          1.8201e-01,  2.8369e-01, -3.4229e-01,  2.5586e-01, -5.7739e-02,\n",
       "         -3.0908e-01,  6.3354e-02,  2.9224e-01,  4.1992e-01, -3.1763e-01,\n",
       "          7.7820e-02,  2.3608e-01, -3.2959e-01, -4.4189e-01,  8.3252e-02,\n",
       "          3.0542e-01,  1.8958e-01,  3.7085e-01, -7.0679e-02,  2.7393e-01,\n",
       "          3.1372e-02, -2.3206e-01, -2.3694e-01, -1.2659e-01,  2.9565e-01,\n",
       "         -4.9756e-01,  2.9004e-01, -5.3802e-02,  2.2034e-01, -1.1279e-01,\n",
       "          4.4214e-01, -4.0137e-01, -9.4055e-02,  1.9116e-01, -1.9055e-01,\n",
       "          6.3672e-01,  7.4097e-02,  9.7534e-02, -2.2327e-01,  1.8115e-01,\n",
       "         -5.0146e-01, -2.4707e-01,  9.5032e-02, -5.6592e-01, -2.7612e-01,\n",
       "          3.3203e-01, -1.0345e-01, -2.1252e-01, -3.5303e-01,  4.2236e-01,\n",
       "         -4.7485e-02, -2.7319e-01,  4.1077e-02,  2.4017e-02,  2.3242e-01,\n",
       "         -1.0016e-01,  2.9907e-01, -6.4011e-03,  4.8535e-01, -2.1716e-01,\n",
       "         -8.2458e-02, -3.4570e-01, -8.5510e-02,  4.8511e-01, -3.6957e-02,\n",
       "         -3.5962e-01,  2.7161e-02,  3.0273e-01,  3.5474e-01, -3.9014e-01,\n",
       "         -1.2323e-01, -5.1416e-01, -8.8806e-02, -4.9365e-01,  5.7800e-02,\n",
       "         -3.2910e-01,  2.8247e-01, -3.2471e-01, -2.6099e-01, -1.2764e-02,\n",
       "         -4.5044e-01, -3.0908e-01,  5.5518e-01,  6.1005e-02,  4.2236e-01,\n",
       "          1.0150e-01,  2.8076e-01, -1.3184e-01, -1.9604e-01, -5.8301e-01,\n",
       "          3.2690e-01,  1.8933e-01, -3.6938e-01, -1.8445e-01,  1.5515e-01,\n",
       "         -2.1436e-01, -4.0161e-01, -4.1406e-01, -5.2979e-01, -2.1622e-02,\n",
       "         -6.4258e-01, -7.0435e-02, -2.8174e-01, -3.0098e-03,  3.7567e-02,\n",
       "         -4.5923e-01, -3.8257e-01,  2.9980e-01, -2.7759e-01,  3.8013e-01,\n",
       "          8.6670e-02, -2.4084e-01, -5.6152e-02, -1.3892e-01,  8.1909e-02,\n",
       "         -9.4055e-02, -3.5614e-02, -6.4087e-02,  4.7211e-02, -2.4390e-01,\n",
       "         -2.4048e-01,  3.0664e-01,  1.2091e-01,  4.1650e-01, -7.4890e-02,\n",
       "         -3.9551e-01, -3.1299e-01, -9.4482e-02,  4.6814e-02,  2.6550e-02,\n",
       "          2.4300e-03,  8.9661e-02, -1.4575e-01,  6.1981e-02, -7.5134e-02,\n",
       "          3.0591e-01, -1.0376e-01, -6.3477e-02, -9.1309e-02, -3.3765e-01,\n",
       "          4.1235e-01, -4.6704e-01, -1.0541e-01,  8.9111e-01,  2.3364e-01,\n",
       "         -1.3599e-01, -8.3237e-03, -2.7393e-01, -4.6118e-01, -2.8687e-02,\n",
       "         -2.4200e-02,  7.5867e-02, -1.7653e-03, -4.3304e-02,  9.7852e-01,\n",
       "          2.3209e-02, -1.2311e-01, -1.5686e-01,  2.2156e-02,  4.8486e-01,\n",
       "         -1.9458e-01,  3.2544e-01], device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " 'prices': tensor([ 27.,  35., 341.,  32.,  -1.,  -1.,  -1.,  -1.]),\n",
       " 'likes': tensor([2981,  251,  996,  433,   -1,   -1,   -1,   -1]),\n",
       " 'images': tensor([[-0.1040,  0.0625, -0.2549,  ...,  0.6992, -0.6509,  0.1523],\n",
       "         [-0.2839, -0.0278,  0.1654,  ...,  0.7593, -0.2729,  0.5898],\n",
       "         [-0.0986,  0.0822, -0.3530,  ...,  0.8579,  0.2393, -0.2015],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "        device='cuda:0', grad_fn=<CatBackward0>),\n",
       " 'image_gt': tensor([ 2.0752e-01,  1.4238e-03,  7.1068e-03, -8.1604e-02,  1.1255e-01,\n",
       "         -5.4248e-01, -3.8940e-02,  2.5073e-01,  3.1519e-01,  3.2446e-01,\n",
       "         -9.0515e-02, -8.5547e-01,  6.6797e-01, -3.0884e-01,  5.6488e-02,\n",
       "          3.8257e-01,  5.0293e-01,  5.7159e-02, -6.0303e-01, -4.9146e-01,\n",
       "         -6.4014e-01,  3.9941e-01,  4.0112e-01, -3.3667e-01,  3.5498e-01,\n",
       "         -1.8335e-01, -2.8564e-01, -5.7324e-01,  1.2891e-01,  7.7393e-02,\n",
       "         -3.5229e-01,  2.6221e-01,  5.9277e-01, -5.1025e-01, -3.5522e-01,\n",
       "         -3.7598e-01, -8.6572e-01,  5.5237e-02, -2.8638e-01, -2.4976e-01,\n",
       "         -6.4148e-02, -2.3865e-01, -4.1895e-01, -3.2324e-01,  5.6982e-01,\n",
       "          1.0918e+00,  4.0381e-01,  2.0984e-01, -1.1304e-01, -1.4172e-01,\n",
       "         -2.8784e-01, -2.1558e-01,  2.1936e-01, -2.3633e-01, -1.3672e-01,\n",
       "          1.2201e-01,  6.5918e-01, -5.6915e-02,  2.0325e-01,  2.0935e-01,\n",
       "         -2.7612e-01,  4.2920e-01,  3.6548e-01,  8.2153e-02,  2.1765e-01,\n",
       "          2.3816e-01,  4.0222e-02, -1.1237e-01, -5.2734e-02, -1.2749e-02,\n",
       "         -1.1090e-01,  3.8116e-02,  2.6440e-01, -2.1875e-01,  1.8713e-01,\n",
       "         -6.4758e-02,  1.7322e-01,  9.8038e-04, -2.1411e-01,  5.4077e-02,\n",
       "          1.5967e-01,  5.0888e-03,  4.4556e-02, -3.0835e-01,  1.5698e-01,\n",
       "          3.3722e-02, -8.6523e-01, -1.1438e-01, -1.7197e-02, -8.4900e-02,\n",
       "         -2.1820e-03, -5.9418e-02, -6.6953e+00,  5.3516e-01,  1.6272e-01,\n",
       "          5.4346e-01,  1.6272e-01, -8.2336e-02, -6.1523e-01, -3.9795e-02,\n",
       "          2.6978e-01,  1.4746e-01, -1.0327e-01, -1.8079e-01, -3.3594e-01,\n",
       "          1.7285e-01, -6.1302e-03, -4.7546e-02, -8.4457e-03,  2.4994e-02,\n",
       "          4.9194e-01, -3.4985e-01, -3.4448e-01,  9.0942e-02,  6.8726e-02,\n",
       "          3.3838e-01,  2.4719e-01, -1.6492e-01, -2.3401e-01, -2.1271e-02,\n",
       "          2.4829e-01, -2.6001e-01, -6.1572e-01, -1.8196e-03,  3.2715e-01,\n",
       "          3.1812e-01, -3.8635e-02,  2.4756e-01,  1.0071e-01,  2.9224e-01,\n",
       "          1.4734e-01,  1.2665e-03, -7.9285e-02,  9.7900e-01,  2.5806e-01,\n",
       "         -3.9948e-02, -1.5198e-01, -4.0771e-02, -4.3506e-01, -5.3558e-02,\n",
       "         -3.2202e-01,  3.6304e-01, -1.8762e-01, -2.8906e-01,  5.2826e-02,\n",
       "         -1.9373e-01,  1.2805e-01,  1.9910e-01, -3.4985e-01, -7.5732e-01,\n",
       "         -4.0314e-02, -1.6980e-01,  1.6094e+00,  4.5471e-02,  2.6709e-01,\n",
       "          1.4819e-01,  1.0681e-02,  4.8560e-01, -2.9199e-01, -2.3694e-01,\n",
       "          1.0864e-01,  9.9487e-02,  2.3511e-01,  3.4271e-02, -3.2202e-01,\n",
       "          3.2153e-01,  5.6689e-01,  5.6702e-02,  4.9780e-01,  4.5068e-01,\n",
       "         -3.2837e-01,  4.5483e-01, -6.4209e-01,  1.6284e-01,  7.1045e-02,\n",
       "          9.9731e-02,  1.0322e+00, -2.6416e-01,  3.9941e-01,  3.9185e-02,\n",
       "          9.1614e-02, -6.6699e-01,  7.0410e-01, -1.0962e-01, -1.4050e-01,\n",
       "          1.6830e-02,  5.7861e-01, -1.6565e-01, -6.7688e-02,  2.0950e-02,\n",
       "         -5.8887e-01, -4.9414e-01,  2.7710e-01,  3.1494e-01,  6.2500e-01,\n",
       "         -3.8257e-01, -1.1151e-01, -1.2238e-02, -6.1475e-01,  1.6589e-01,\n",
       "          7.5867e-02, -3.8623e-01, -6.8298e-02,  4.5752e-01,  1.6504e-01,\n",
       "         -2.3026e-02, -5.6396e-01, -2.3022e-01, -1.2433e-01, -5.1465e-01,\n",
       "         -6.3477e-02,  7.0020e-01, -6.4636e-02, -5.8441e-02, -1.4417e-01,\n",
       "          1.1932e-01, -6.7041e-01,  4.0698e-01,  5.5566e-01, -2.9272e-01,\n",
       "          3.1323e-01, -6.8018e-01,  5.1758e-01,  3.1006e-01,  2.2205e-01,\n",
       "          5.9937e-02,  3.2959e-03,  1.5198e-01, -1.8872e-01,  5.9229e-01,\n",
       "          6.9482e-01, -4.5239e-01,  8.0200e-02,  4.4702e-01, -1.0358e-01,\n",
       "         -7.9297e-01, -2.3499e-01,  1.5991e-01,  5.1117e-02, -3.4717e-01,\n",
       "          6.0889e-01,  9.5154e-02, -2.9541e-01, -2.9736e-01,  3.3661e-02,\n",
       "          2.9517e-01,  6.4160e-01,  1.0938e-01, -2.6001e-01,  2.1118e-01,\n",
       "          4.2627e-01,  1.0480e-01,  1.4905e-01, -5.8887e-01,  1.4297e-02,\n",
       "          6.1475e-01,  4.0955e-02, -4.7241e-02, -1.3018e+00, -7.2937e-02,\n",
       "          1.6626e-01,  3.0005e-01, -3.5205e-01,  7.6953e-01, -3.4717e-01,\n",
       "          3.5083e-01, -2.0068e-01,  1.6882e-01,  2.8125e-01, -3.4814e-01,\n",
       "         -2.1936e-01, -2.6953e-01,  3.2745e-02, -1.8909e-01,  1.7261e-01,\n",
       "          2.1277e-01, -5.9570e-01,  3.8528e-03, -9.6313e-02, -5.2148e-01,\n",
       "         -3.8013e-01,  4.1992e-01, -5.8984e-01,  1.9946e-01, -3.5205e-01,\n",
       "         -2.2602e-03, -6.5918e-01, -2.4948e-02,  4.2236e-01, -2.7368e-01,\n",
       "          2.1057e-01,  3.2861e-01,  1.5344e-01, -5.4718e-02,  2.5537e-01,\n",
       "         -5.0928e-01, -2.7637e-01, -5.5756e-02,  4.0137e-01,  1.5137e-01,\n",
       "          4.3604e-01, -3.3374e-01,  5.8936e-01,  6.1279e-02, -1.9153e-01,\n",
       "         -1.2903e-01,  2.2766e-01,  2.4927e-01,  1.8848e-01,  9.7412e-02,\n",
       "          1.9348e-01,  7.3059e-02,  9.7949e-01,  1.3062e-01,  5.1416e-01,\n",
       "         -2.7148e-01,  1.8945e-01,  1.0370e-01, -1.3806e-01, -3.3447e-01,\n",
       "         -3.2568e-01,  1.2812e+00, -2.6294e-01, -5.0537e-01,  7.0435e-02,\n",
       "         -2.4316e-01, -1.7480e-01, -2.3438e-02,  2.2888e-03,  1.7615e-01,\n",
       "          2.8027e-01,  4.4702e-01, -6.3281e-01, -2.3608e-01, -8.0627e-02,\n",
       "         -5.2588e-01, -3.0273e-01,  3.2867e-02, -5.4297e-01, -1.9922e-01,\n",
       "         -5.1270e-01, -2.2986e-01,  3.5352e-01,  3.9697e-01, -8.7646e-02,\n",
       "          1.0962e-01,  6.4893e-01,  6.3281e-01,  4.3188e-01,  1.0443e-01,\n",
       "          5.3955e-01,  2.1619e-01,  8.5022e-02, -1.9629e-01,  2.7881e-01,\n",
       "         -3.4760e-02, -2.8589e-01,  1.1553e+00, -1.7322e-01,  2.6318e-01,\n",
       "          8.4766e-01, -8.7219e-02, -3.4985e-01, -1.7468e-01, -1.0352e-01,\n",
       "         -2.3743e-01,  2.9468e-01,  1.8447e+00,  3.3301e-01,  1.7899e-02,\n",
       "         -1.3855e-01, -3.1567e-01,  1.5173e-01, -1.6089e-01,  3.2666e-01,\n",
       "         -2.2253e-01,  1.9727e-01, -4.6069e-01, -8.5010e-01,  7.1191e-01,\n",
       "         -3.4985e-01, -4.4971e-01, -2.9321e-01,  4.4312e-01, -4.0503e-01,\n",
       "          2.7954e-01,  7.1582e-01,  1.9608e-02, -3.2251e-01, -1.1389e-01,\n",
       "          2.5528e-02, -1.4832e-01,  6.7749e-02, -7.0068e-02, -9.1309e-01,\n",
       "          1.1151e-01,  3.4943e-02,  2.5659e-01,  5.5127e-01, -1.8115e-01,\n",
       "         -2.8839e-03, -1.8958e-01,  5.6543e-01,  8.2947e-02, -7.5378e-02,\n",
       "         -4.0234e-01, -2.2263e-02,  4.9365e-01,  2.3059e-01,  2.1802e-01,\n",
       "         -1.2158e-01, -8.4290e-02, -8.1787e-02, -1.0553e-01, -2.4707e-01,\n",
       "          6.2469e-02, -6.3672e-01,  1.2006e-01, -1.7102e-01, -9.7900e-02,\n",
       "         -1.9678e-01, -1.4331e-01,  5.3809e-01,  7.0459e-01,  1.5698e-01,\n",
       "         -1.4148e-01, -2.4512e-01, -5.1636e-02, -1.0293e+00,  6.2012e-01,\n",
       "         -3.4424e-02, -2.0615e-02,  5.1660e-01, -9.1675e-02,  2.9199e-01,\n",
       "          6.1874e-03,  1.0632e-01,  5.0079e-02,  1.6760e-01, -7.3303e-02,\n",
       "          1.1847e-01,  5.5957e-01, -6.3110e-02,  1.9238e-01, -3.0444e-01,\n",
       "         -4.6631e-01, -7.8003e-02, -5.4565e-02, -2.5513e-01, -1.1078e-01,\n",
       "         -2.4390e-01, -1.6922e-02, -1.6187e-01,  2.1423e-01, -1.9885e-01,\n",
       "         -1.6003e-01,  2.9053e-01,  3.4637e-02,  2.1814e-01, -7.4658e-01,\n",
       "          2.1152e-03, -4.3286e-01,  2.8223e-01,  1.1798e-01, -2.5375e-02,\n",
       "          1.6321e-01, -4.2651e-01,  2.1790e-01, -2.8052e-01,  2.6154e-02,\n",
       "         -1.7065e-01,  2.6550e-02, -3.6621e-01, -1.0437e-01, -2.9883e-01,\n",
       "         -1.7847e-01, -2.7783e-01,  4.6417e-02,  9.8816e-02,  3.6163e-02,\n",
       "          2.3209e-02, -1.8448e-02,  1.0553e-01,  2.6001e-01,  4.3915e-02,\n",
       "          2.3071e-01, -1.1389e-01,  2.7368e-01,  1.1920e-01,  5.2795e-03,\n",
       "         -1.1749e-01, -2.7563e-01,  4.3243e-02, -7.6025e-01, -2.3767e-01,\n",
       "         -1.6370e-01,  3.9185e-01, -1.9080e-01,  5.7343e-02, -4.9487e-01,\n",
       "          2.1643e-01,  5.5811e-01,  1.8604e-01,  4.3042e-01,  5.4932e-01,\n",
       "         -4.4312e-01,  1.0089e-01, -2.5589e-02, -1.1481e-01,  7.7539e-01,\n",
       "          1.5125e-01,  2.2058e-01], device='cuda:0', grad_fn=<SliceBackward0>),\n",
       " 'set_id': 125368926,\n",
       " 'valid_idx': 3,\n",
       " 'gt_idx': 3}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_collate_fn(batch, test=False):\n",
    "#     texts = [item[\"texts\"] for item in batch]\n",
    "#     price = [item[\"price\"] for item in batch]         \n",
    "#     likes = [item[\"likes\"] for item in batch]         \n",
    "#     images = [item[\"images\"] for item in batch]        \n",
    "#     set_id = [item[\"set_id\"] for item in batch]       \n",
    "       \n",
    "#     if test:\n",
    "#         question = [item[\"question\"] for item in batch] \n",
    "#         return {\n",
    "#             \"texts\": texts,\n",
    "#             \"price\": price,\n",
    "#             \"likes\": likes,\n",
    "#             \"images\": images,\n",
    "#             \"set_id\": set_id,\n",
    "#             \"question\": question,\n",
    "#         }\n",
    "#     else: \n",
    "#         return {\n",
    "#             \"texts\": texts,\n",
    "#             \"price\": price,\n",
    "#             \"likes\": likes,\n",
    "#             \"images\": images,\n",
    "#             \"set_id\": set_id\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from model.models import Multifusion, MultiLSTM\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['texts', 'text_gt', 'prices', 'likes', 'images', 'image_gt', 'set_id', 'valid_idx', 'gt_idx'])\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "\n",
    "for batch_idx, batch in enumerate(train_dataloader):\n",
    "    print(batch.keys())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_dataloader\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = Multifusion().to(device)\n",
    "lstm = MultiLSTM(input_size=512, hidden_size=512, num_layers=1, bidirectional=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m image_embedding\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     20\u001b[0m image_gt \u001b[38;5;241m=\u001b[39m image_embedding[torch\u001b[38;5;241m.\u001b[39marange(batch_size), gt_idx, :]\n\u001b[1;32m---> 21\u001b[0m text_gt \u001b[38;5;241m=\u001b[39m \u001b[43mtext_embedding\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     23\u001b[0m image_context, text_context \u001b[38;5;241m=\u001b[39m lstm(image_embedding, text_embedding, gt_idx)\n\u001b[0;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m cosine_similarity_loss(image_context, image_gt, text_context, text_gt)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=1e-3)\n",
    "\n",
    "def cosine_similarity_loss(image_context, image_gt, text_context, text_gt):\n",
    "    image_loss = 1 - F.cosine_similarity(image_context, image_gt, dim=-1).mean()\n",
    "    text_loss = 1 - F.cosine_similarity(text_context, text_gt, dim=-1).mean()\n",
    "    total_loss = (image_loss + text_loss) / 2\n",
    "    return total_loss\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        image_embedding = batch['images'].to(device)\n",
    "        text_embedding = batch['texts'].to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        image_context, text_context = lstm(image_embedding, text_embedding, gt_idx)\n",
    "\n",
    "        loss = cosine_similarity_loss(image_context, image_gt, text_context, text_gt)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "torch.save(lstm.state_dict(), \"multilstm_model_epoch50.pth\")\n",
    "print(\"Model saved to multilstm_model_epoch50.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.models import Multifusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
